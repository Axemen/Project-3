{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_caller', 'Maker', 'distilled', 'age in cast', 'ABV', 'Blended',\n",
       "       'Bourbon', 'Flavored', 'Other', 'Rye', 'Scotch', 'single blended grain',\n",
       "       'single blended malt', 'world', 'review score', 'price', 'style',\n",
       "       'country', 'row_other', 'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "rawData = pd.read_csv(os.path.join(\"clean-data\",\"Whiskey_data\",\"Whiskey_Advocate_All_scraped_KHupdate-with-description.csv\"), encoding='iso-8859-1' )\n",
    "rawData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_caller</th>\n",
       "      <th>Maker</th>\n",
       "      <th>distilled</th>\n",
       "      <th>age in cast</th>\n",
       "      <th>ABV</th>\n",
       "      <th>Blended</th>\n",
       "      <th>Bourbon</th>\n",
       "      <th>Flavored</th>\n",
       "      <th>Other</th>\n",
       "      <th>Rye</th>\n",
       "      <th>Scotch</th>\n",
       "      <th>single blended grain</th>\n",
       "      <th>single blended malt</th>\n",
       "      <th>world</th>\n",
       "      <th>review score</th>\n",
       "      <th>price</th>\n",
       "      <th>style</th>\n",
       "      <th>country</th>\n",
       "      <th>row_other</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnnie Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>225</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>UK</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Magnificently powerful and intense. Caramels, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Black Bowmore</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>42 year old</td>\n",
       "      <td>40.50%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>4500</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>UK</td>\n",
       "      <td>3.0</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bowmore</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46 year old</td>\n",
       "      <td>42.90%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>13500</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>UK</td>\n",
       "      <td>4.0</td>\n",
       "      <td>There have been some legendary Bowmores from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Compass Box</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30 years old</td>\n",
       "      <td>53.40%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>325</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>UK</td>\n",
       "      <td>5.0</td>\n",
       "      <td>With a name inspired by a 1926 Buster Keaton m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chivas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96</td>\n",
       "      <td>160</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>UK</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Captivating, enticing, and wonderfully charmin...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_caller           Maker  distilled   age in cast     ABV  Blended  \\\n",
       "0           1  Johnnie Walker        NaN           NaN  40.00%        1   \n",
       "1           2   Black Bowmore     1964.0   42 year old  40.50%        0   \n",
       "2           3         Bowmore        NaN   46 year old  42.90%        0   \n",
       "3           4     Compass Box        NaN  30 years old  53.40%        1   \n",
       "4           5          Chivas        NaN           NaN  40.00%        1   \n",
       "\n",
       "   Bourbon  Flavored  Other  Rye  Scotch  single blended grain  \\\n",
       "0        0         0      0    0       1                     0   \n",
       "1        0         0      0    0       1                     0   \n",
       "2        0         0      0    0       1                     0   \n",
       "3        0         0      0    0       1                     0   \n",
       "4        0         0      0    0       1                     0   \n",
       "\n",
       "   single blended malt  world  review score  price  \\\n",
       "0                    0      0            97    225   \n",
       "1                    1      0            97   4500   \n",
       "2                    1      0            97  13500   \n",
       "3                    1      0            96    325   \n",
       "4                    1      0            96    160   \n",
       "\n",
       "                        style country  row_other  \\\n",
       "0       Blended Scotch Whisky      UK        2.0   \n",
       "1          Single Malt Scotch      UK        3.0   \n",
       "2          Single Malt Scotch      UK        4.0   \n",
       "3  Blended Malt Scotch Whisky      UK        5.0   \n",
       "4  Blended Malt Scotch Whisky      UK        6.0   \n",
       "\n",
       "                                         description  \n",
       "0  Magnificently powerful and intense. Caramels, ...  \n",
       "1  What impresses me most is how this whisky evol...  \n",
       "2  There have been some legendary Bowmores from t...  \n",
       "3  With a name inspired by a 1926 Buster Keaton m...  \n",
       "4  Captivating, enticing, and wonderfully charmin...  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head data\n",
    "rawData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review points bin\n",
    "rp_bins = [(0,75), (75,80), (80,85), (85,90), (90,95), (95, 100)]\n",
    "\n",
    "# find bin based on value\n",
    "def find_rp_bin(value):\n",
    "    \n",
    "    for i in range(0, len(rp_bins)):\n",
    "        if rp_bins[i][0] <= value < rp_bins[i][1]:\n",
    "            return rp_bins[i][0] #lower end of the bin is returned\n",
    "    return -1\n",
    "\n",
    "# fill y value\n",
    "rawData['rp_bins'] = rawData['review score'].apply(find_rp_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price bin\n",
    "price_bins = [(0,10), (10,25), (25,50), (50,75), (75,250), (250,500), (500,1000000)]\n",
    "\n",
    "# find bin based on value\n",
    "def find_price_bin(value):\n",
    "    price = 0\n",
    "    for i in range(0, len(price_bins)):\n",
    "        if price_bins[i][0] <= value < price_bins[i][1]:\n",
    "            return price_bins[i][0] #lower end of the bin is returned\n",
    "    return -1\n",
    "\n",
    "# \n",
    "rawData['price_bins'] = rawData['price'].apply(find_price_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "rawData.dropna(how = 'all',inplace=True)\n",
    "rawData.dropna(subset=['description', 'price'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 79 135 157000\n"
     ]
    }
   ],
   "source": [
    "# price quartiles\n",
    "Q1 = np.percentile(rawData['price'],25,axis=0, interpolation='lower')\n",
    "Q2 = np.percentile(rawData['price'],50,axis=0, interpolation='lower')\n",
    "Q3 = np.percentile(rawData['price'],75,axis=0, interpolation='lower')\n",
    "Q4 = np.percentile(rawData['price'],100,axis=0, interpolation='lower')\n",
    "print(Q1,Q2,Q3,Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop quartiles Q1 / Q4\n",
    "indexNames = rawData[ (rawData['price'] < Q1)].index\n",
    "rawData.drop(indexNames , inplace=True)\n",
    "indexNames = rawData[ (rawData['price'] >= Q3)].index\n",
    "rawData.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_caller</th>\n",
       "      <th>Maker</th>\n",
       "      <th>distilled</th>\n",
       "      <th>age in cast</th>\n",
       "      <th>ABV</th>\n",
       "      <th>Blended</th>\n",
       "      <th>Bourbon</th>\n",
       "      <th>Flavored</th>\n",
       "      <th>Other</th>\n",
       "      <th>Rye</th>\n",
       "      <th>...</th>\n",
       "      <th>single blended malt</th>\n",
       "      <th>world</th>\n",
       "      <th>review score</th>\n",
       "      <th>price</th>\n",
       "      <th>style</th>\n",
       "      <th>country</th>\n",
       "      <th>row_other</th>\n",
       "      <th>description</th>\n",
       "      <th>rp_bins</th>\n",
       "      <th>price_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Compass Box</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48.90%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>105</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>UK</td>\n",
       "      <td>14.0</td>\n",
       "      <td>A marriage of three different single malts, ag...</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Compass Box</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>54.70%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>120</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>UK</td>\n",
       "      <td>15.0</td>\n",
       "      <td>As you 'd expect, solid peat is the first thin...</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Chivas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18 year old</td>\n",
       "      <td>40.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>UK</td>\n",
       "      <td>17.0</td>\n",
       "      <td>An essay in balance on both the aroma and pala...</td>\n",
       "      <td>95</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Ardbeg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.10%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>UK</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Part of the permanent Ardbeg range since 2008,...</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41</td>\n",
       "      <td>Compass Box</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>65</td>\n",
       "      <td>Blended Malt Scotch Whisky</td>\n",
       "      <td>UK</td>\n",
       "      <td>42.0</td>\n",
       "      <td>The formula for this whisky has changed slight...</td>\n",
       "      <td>90</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    row_caller        Maker  distilled  age in cast     ABV  Blended  Bourbon  \\\n",
       "12          13  Compass Box        NaN          NaN  48.90%        1        0   \n",
       "13          14  Compass Box        NaN          NaN  54.70%        1        0   \n",
       "15          16       Chivas        NaN  18 year old  40.00%        1        0   \n",
       "18          19       Ardbeg        NaN          NaN  57.10%        0        0   \n",
       "39          41  Compass Box        NaN          NaN  46.00%        1        0   \n",
       "\n",
       "    Flavored  Other  Rye  ...  single blended malt  world  review score  \\\n",
       "12         0      0    0  ...                    1      0            95   \n",
       "13         0      0    0  ...                    0      0            95   \n",
       "15         0      0    0  ...                    0      0            95   \n",
       "18         0      0    0  ...                    1      0            95   \n",
       "39         0      0    0  ...                    1      0            94   \n",
       "\n",
       "    price                       style  country row_other  \\\n",
       "12    105  Blended Malt Scotch Whisky       UK      14.0   \n",
       "13    120       Blended Scotch Whisky       UK      15.0   \n",
       "15     70       Blended Scotch Whisky       UK      17.0   \n",
       "18     90          Single Malt Scotch       UK      20.0   \n",
       "39     65  Blended Malt Scotch Whisky       UK      42.0   \n",
       "\n",
       "                                          description  rp_bins price_bins  \n",
       "12  A marriage of three different single malts, ag...       95         75  \n",
       "13  As you 'd expect, solid peat is the first thin...       95         75  \n",
       "15  An essay in balance on both the aroma and pala...       95         50  \n",
       "18  Part of the permanent Ardbeg range since 2008,...       95         75  \n",
       "39  The formula for this whisky has changed slight...       90         50  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific libraries\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=False, max_df=1.0, max_features=None, min_df=0,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize description: take the words of each description and create a vocabulary of all the unique words in the descriptions.\n",
    "# This vocabulary can then be used to create a feature vector of the count of the words:\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(rawData['description'])\n",
    "# vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vector with all words for each description = Bag-of-words (BOW) model\n",
    "vectorizer.transform(rawData['description']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split data\n",
    "X_LR_rp = rawData['description'].values\n",
    "y_LR_rp_values = rawData['review score'].values\n",
    "\n",
    "X_LR_rp_train, X_LR_rp_test, y_LR_rp_values_train, y_LR_rp_values_test = train_test_split(X_LR_rp, y_LR_rp_values, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_LR_rp_train)\n",
    "X_LR_rp_v_train = vectorizer.transform(X_LR_rp_train)\n",
    "X_LR_rp_v_test  = vectorizer.transform(X_LR_rp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Points: Logistic Regression: values: Accuracy: 0.10847457627118644\n"
     ]
    }
   ],
   "source": [
    "# logistic regression classification model\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_LR_rp_v_train, y_LR_rp_values_train) # vectorized training data\n",
    "score_LR_rp_values = classifier.score(X_LR_rp_v_test, y_LR_rp_values_test)\n",
    "print(\"Review Points:\",\"Logistic Regression:\",\"values:\",\"Accuracy:\",score_LR_rp_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split data\n",
    "X_LR_rp = rawData['description'].values\n",
    "y_LR_rp_bins = rawData['rp_bins'].values\n",
    "\n",
    "X_LR_rp_train, X_LR_rp_test, y_LR_rp_bins_train, y_LR_rp_bins_test = train_test_split(X_LR_rp, y_LR_rp_bins, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_LR_rp_train)\n",
    "X_LR_rp_v_train = vectorizer.transform(X_LR_rp_train)\n",
    "X_LR_rp_v_test  = vectorizer.transform(X_LR_rp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Points: Logistic Regression: bins: Accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "# logistic regression classification model\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_LR_rp_v_train, y_LR_rp_bins_train) # vectorized training data\n",
    "score_LR_rp_bins = classifier.score(X_LR_rp_v_test, y_LR_rp_values_test)\n",
    "print(\"Review Points:\",\"Logistic Regression:\",\"bins:\",\"Accuracy:\",score_LR_rp_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split data\n",
    "X_RF_rp = rawData['description'].values\n",
    "y_RF_rp_values = rawData['review score'].values\n",
    "\n",
    "X_RF_rp_train, X_RF_rp_test, y_RF_rp_values_train, y_RF_rp_values_test = train_test_split(X_RF_rp, y_RF_rp_values, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_RF_rp_train)\n",
    "X_RF_rp_v_train = vectorizer.transform(X_RF_rp_train)\n",
    "X_RF_rp_v_test  = vectorizer.transform(X_RF_rp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Points: Random forests: values: Accuracy: 0.08983050847457627\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "rf_rp = RandomForestClassifier(n_estimators=200)\n",
    "rf_rp_values = rf_rp.fit(X_RF_rp_v_train, y_RF_rp_values_train)\n",
    "score_RF_rp_values = rf_rp_values.score(X_RF_rp_v_test, y_RF_rp_values_test)\n",
    "print(\"Review Points:\",\"Random forests:\",\"values:\",\"Accuracy:\",score_RF_rp_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split data\n",
    "X_RF_rp = rawData['description'].values\n",
    "y_RF_rp_bins = rawData['rp_bins'].values\n",
    "\n",
    "X_RF_rp_train, X_RF_rp_test, y_RF_rp_bins_train, y_RF_rp_bins_test = train_test_split(X_RF_rp, y_RF_rp_bins, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_RF_rp_train)\n",
    "X_RF_rp_v_train = vectorizer.transform(X_RF_rp_train)\n",
    "X_RF_rp_v_test  = vectorizer.transform(X_RF_rp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Points: Random forests: bins: Accuracy: 0.4864406779661017\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "rf_rp = RandomForestClassifier(n_estimators=200)\n",
    "rf_rp_bins = rf_rp.fit(X_RF_rp_v_train, y_RF_rp_bins_train)\n",
    "score_RF_rp_bins = rf_rp_bins.score(X_RF_rp_v_test, y_RF_rp_bins_test)\n",
    "print(\"Review Points:\",\"Random forests:\",\"bins:\",\"Accuracy:\",score_RF_rp_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Multinomial\n",
    "It is used for discrete counts. For example, let’s say, we have a text classification problem. Here we can consider bernoulli trials which is one step further and instead of “word occurring in the document”, we have “count how often word occurs in the document”, you can think of it as “number of times outcome number x_i is observed over the n trials”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_NBM_rp = rawData['description'].values\n",
    "y_NBM_rp_values = rawData['review score'].values\n",
    "\n",
    "X_NBM_rp_train, X_NBM_rp_test, y_NBM_rp_values_train, y_NBM_rp_values_test = train_test_split(X_NBM_rp, y_NBM_rp_values, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_NBM_rp_train)\n",
    "X_NBM_rp_v_train = vectorizer.transform(X_NBM_rp_train)\n",
    "X_NBM_rp_v_test  = vectorizer.transform(X_NBM_rp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Points: Naive Bayes - Multinomial: values: Accuracy: 0.08983050847457627\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Create a Multinomial Classifier\n",
    "model_NBM_rp = MultinomialNB()\n",
    "# Train the model using the training sets\n",
    "model_NBM_rp.fit(X_NBM_rp_v_train,y_NBM_rp_values_train)\n",
    "#Predict Output \n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "y_NBM_rp_values_prediction = model_NBM_rp.predict(X_NBM_rp_v_test)\n",
    "score_NBM_rp_values = metrics.accuracy_score(y_NBM_rp_values_test, y_NBM_rp_values_prediction)\n",
    "print(\"Review Points:\",\"Naive Bayes - Multinomial:\",\"values:\",\"Accuracy:\",score_NBM_rp_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_NBM_rp = rawData['description'].values\n",
    "y_NBM_rp_bins = rawData['rp_bins'].values\n",
    "\n",
    "X_NBM_rp_train, X_NBM_rp_test, y_NBM_rp_bins_train, y_NBM_rp_bins_test = train_test_split(X_NBM_rp, y_NBM_rp_bins, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_NBM_rp_train)\n",
    "X_NBM_rp_v_train = vectorizer.transform(X_NBM_rp_train)\n",
    "X_NBM_rp_v_test  = vectorizer.transform(X_NBM_rp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Points: Naive Bayes - Multinomial: bins: Accuracy: 0.5050847457627119\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Create a Multinomial Classifier\n",
    "model_NBM_rp = MultinomialNB()\n",
    "# Train the model using the training sets\n",
    "model_NBM_rp.fit(X_NBM_rp_v_train,y_NBM_rp_bins_train)\n",
    "#Predict Output \n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "y_NBM_rp_bins_prediction = model_NBM_rp.predict(X_NBM_rp_v_test)\n",
    "score_NBM_rp_bins = metrics.accuracy_score(y_NBM_rp_bins_test, y_NBM_rp_bins_prediction)\n",
    "print(\"Review Points:\",\"Naive Bayes - Multinomial:\",\"bins:\",\"Accuracy:\",score_NBM_rp_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Bernoulli\n",
    "The binomial model is useful if your feature vectors are binary (i.e. zeros and ones). One application would be text classification with ‘bag of words’ model where the 1s & 0s are “word occurs in the document” and “word does not occur in the document” respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_NBB_rp = rawData['description'].values\n",
    "y_NBB_rp_values = rawData['review score'].values\n",
    "\n",
    "X_NBB_rp_train, X_NBB_rp_test, y_NBB_rp_values_train, y_NBB_rp_values_test = train_test_split(X_NBB_rp, y_NBB_rp_values, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_NBB_rp_train)\n",
    "X_NBB_rp_v_train = vectorizer.transform(X_NBB_rp_train)\n",
    "X_NBB_rp_v_test  = vectorizer.transform(X_NBB_rp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Points: Naive Bayes - Bernoulli: values: Accuracy: 0.09152542372881356\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#Create a BernoulliNB Classifier\n",
    "model_NBB_rp = BernoulliNB()\n",
    "# Train the model using the training sets\n",
    "model_NBB_rp.fit(X_NBB_rp_v_train,y_NBB_rp_values_train)\n",
    "#Predict Output \n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "y_NBB_rp_values_prediction = model_NBB_rp.predict(X_NBB_rp_v_test)\n",
    "score_NBB_rp_values = metrics.accuracy_score(y_NBB_rp_values_test, y_NBB_rp_values_prediction)\n",
    "print(\"Review Points:\",\"Naive Bayes - Bernoulli:\",\"values:\",\"Accuracy:\",score_NBB_rp_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_NBB_rp = rawData['description'].values\n",
    "y_NBB_rp_bins = rawData['rp_bins'].values\n",
    "\n",
    "X_NBB_rp_train, X_NBB_rp_test, y_NBB_rp_bins_train, y_NBB_rp_bins_test = train_test_split(X_NBB_rp, y_NBB_rp_bins, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_NBB_rp_train)\n",
    "X_NBB_rp_v_train = vectorizer.transform(X_NBB_rp_train)\n",
    "X_NBB_rp_v_test  = vectorizer.transform(X_NBB_rp_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Points: Naive Bayes - Bernoulli: bins: Accuracy: 0.488135593220339\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#Create a BernoulliNB Classifier\n",
    "model_NBB_rp = BernoulliNB()\n",
    "# Train the model using the training sets\n",
    "model_NBB_rp.fit(X_NBB_rp_v_train,y_NBB_rp_bins_train)\n",
    "#Predict Output \n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "y_NBB_rp_bins_prediction = model_NBB_rp.predict(X_NBB_rp_v_test)\n",
    "score_NBB_rp_bins = metrics.accuracy_score(y_NBB_rp_bins_test, y_NBB_rp_bins_prediction)\n",
    "print(\"Review Points:\",\"Naive Bayes - Bernoulli:\",\"bins:\",\"Accuracy:\",score_NBB_rp_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific libraries\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=False, max_df=1.0, max_features=None, min_df=0,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize description: take the words of each description and create a vocabulary of all the unique words in the descriptions.\n",
    "# This vocabulary can then be used to create a feature vector of the count of the words:\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(rawData['description'])\n",
    "# vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create vector with all words for each description = Bag-of-words (BOW) model\n",
    "vectorizer.transform(rawData['description']).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split data\n",
    "X_LR_price = rawData['description'].values\n",
    "y_LR_price_values = rawData['price'].values\n",
    "\n",
    "X_LR_price_train, X_LR_price_test, y_LR_price_values_train, y_LR_price_values_test = train_test_split(X_LR_price, y_LR_price_values, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_LR_price_train)\n",
    "X_LR_price_v_train = vectorizer.transform(X_LR_price_train)\n",
    "X_LR_price_v_test  = vectorizer.transform(X_LR_price_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: Logistic Regression: values: Accuracy: 0.0847457627118644\n"
     ]
    }
   ],
   "source": [
    "# logistic regression classification model\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_LR_price_v_train, y_LR_price_values_train) # vectorized training data\n",
    "score_LR_price_values = classifier.score(X_LR_price_v_test, y_LR_price_values_test)\n",
    "print(\"Price:\",\"Logistic Regression:\",\"values:\",\"Accuracy:\",score_LR_price_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split data\n",
    "X_LR_price = rawData['description'].values\n",
    "y_LR_price_bins = rawData['price_bins'].values\n",
    "\n",
    "X_LR_price_train, X_LR_price_test, y_LR_price_bins_train, y_LR_price_bins_test = train_test_split(X_LR_price, y_LR_price_bins, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_LR_price_train)\n",
    "X_LR_price_v_train = vectorizer.transform(X_LR_price_train)\n",
    "X_LR_price_v_test  = vectorizer.transform(X_LR_price_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: Logistic Regression: bins: Accuracy: 0.5898305084745763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# logistic regression classification model\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_LR_price_v_train, y_LR_price_bins_train) # vectorized training data\n",
    "score_LR_price_bins = classifier.score(X_LR_price_v_test, y_LR_price_bins_test)\n",
    "print(\"Price:\",\"Logistic Regression:\",\"bins:\",\"Accuracy:\",score_LR_price_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split data\n",
    "X_RF_price = rawData['description'].values\n",
    "y_RF_price_values = rawData['price'].values\n",
    "\n",
    "X_RF_price_train, X_RF_price_test, y_RF_price_values_train, y_RF_price_values_test = train_test_split(X_RF_price, y_RF_price_values, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_RF_price_train)\n",
    "X_RF_price_v_train = vectorizer.transform(X_RF_price_train)\n",
    "X_RF_price_v_test  = vectorizer.transform(X_RF_price_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: Random forests: values: Accuracy: 0.12372881355932204\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "rf_price = RandomForestClassifier(n_estimators=200)\n",
    "rf_price_values = rf_price.fit(X_RF_price_v_train, y_RF_price_values_train)\n",
    "score_RF_price_values = rf_price_values.score(X_RF_price_v_test, y_RF_price_values_test)\n",
    "print(\"Price:\",\"Random forests:\",\"values:\",\"Accuracy:\",score_RF_price_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  split data\n",
    "X_RF_price = rawData['description'].values\n",
    "y_RF_price_bins = rawData['price_bins'].values\n",
    "\n",
    "X_RF_price_train, X_RF_price_test, y_RF_price_bins_train, y_RF_price_bins_test = train_test_split(X_RF_price, y_RF_price_bins, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_RF_price_train)\n",
    "X_RF_price_v_train = vectorizer.transform(X_RF_price_train)\n",
    "X_RF_price_v_test  = vectorizer.transform(X_RF_price_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: Random forests: bins: Accuracy: 0.5949152542372881\n"
     ]
    }
   ],
   "source": [
    "# Create a random forest classifier\n",
    "rf_price = RandomForestClassifier(n_estimators=200)\n",
    "rf_price_bins = rf_price.fit(X_RF_price_v_train, y_RF_price_bins_train)\n",
    "score_RF_price_bins = rf_price_bins.score(X_RF_price_v_test, y_RF_price_bins_test)\n",
    "print(\"Price:\",\"Random forests:\",\"bins:\",\"Accuracy:\",score_RF_price_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Multinomial\n",
    "It is used for discrete counts. For example, let’s say, we have a text classification problem. Here we can consider bernoulli trials which is one step further and instead of “word occurring in the document”, we have “count how often word occurs in the document”, you can think of it as “number of times outcome number x_i is observed over the n trials”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_NBM_price = rawData['description'].values\n",
    "y_NBM_price_values = rawData['price'].values\n",
    "\n",
    "X_NBM_price_train, X_NBM_price_test, y_NBM_price_values_train, y_NBM_price_values_test = train_test_split(X_NBM_price, y_NBM_price_values, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_NBM_price_train)\n",
    "X_NBM_price_v_train = vectorizer.transform(X_NBM_price_train)\n",
    "X_NBM_price_v_test  = vectorizer.transform(X_NBM_price_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: Naive Bayes - Multinomial: values: Accuracy: 0.03559322033898305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Create a Multinomial Classifier\n",
    "model_NBM_price = MultinomialNB()\n",
    "# Train the model using the training sets\n",
    "model_NBM_price.fit(X_NBM_price_v_train,y_NBM_price_values_train)\n",
    "#Predict Output \n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "y_NBM_price_values_prediction = model_NBM_rp.predict(X_NBM_price_v_test)\n",
    "score_NBM_price_values = metrics.accuracy_score(y_NBM_price_values_test, y_NBM_price_values_prediction)\n",
    "print(\"Price:\",\"Naive Bayes - Multinomial:\",\"values:\",\"Accuracy:\",score_NBM_price_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_NBM_price = rawData['description'].values\n",
    "y_NBM_price_bins = rawData['price_bins'].values\n",
    "\n",
    "X_NBM_price_train, X_NBM_price_test, y_NBM_price_bins_train, y_NBM_price_bins_test = train_test_split(X_NBM_price, y_NBM_price_bins, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_NBM_price_train)\n",
    "X_NBM_price_v_train = vectorizer.transform(X_NBM_price_train)\n",
    "X_NBM_price_v_test  = vectorizer.transform(X_NBM_price_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price: Naive Bayes - Multinomial: bins: Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "#Create a Multinomial Classifier\n",
    "model_NBM_price = MultinomialNB()\n",
    "# Train the model using the training sets\n",
    "model_NBM_price.fit(X_NBM_price_v_train,y_NBM_price_bins_train)\n",
    "#Predict Output \n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "y_NBM_price_bins_prediction = model_NBM_rp.predict(X_NBM_price_v_test)\n",
    "score_NBM_price_bins = metrics.accuracy_score(y_NBM_price_bins_test, y_NBM_price_bins_prediction)\n",
    "print(\"Price:\",\"Naive Bayes - Multinomial:\",\"bins:\",\"Accuracy:\",score_NBM_price_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes - Bernoulli\n",
    "The binomial model is useful if your feature vectors are binary (i.e. zeros and ones). One application would be text classification with ‘bag of words’ model where the 1s & 0s are “word occurs in the document” and “word does not occur in the document” respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_NBB_price = rawData['description'].values\n",
    "y_NBB_price_values = rawData['price'].values\n",
    "\n",
    "X_NBB_price_train, X_NBB_price_test, y_NBB_price_values_train, y_NBB_price_values_test = train_test_split(X_NBB_price, y_NBB_price_values, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_NBB_price_train)\n",
    "X_NBB_price_v_train = vectorizer.transform(X_NBB_price_train)\n",
    "X_NBB_price_v_test  = vectorizer.transform(X_NBB_price_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Points: Naive Bayes - Bernoulli: values: Accuracy: 0.1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#Create a BernoulliNB Classifier\n",
    "model_NBB_price = BernoulliNB()\n",
    "# Train the model using the training sets\n",
    "model_NBB_price.fit(X_NBB_price_v_train,y_NBB_price_values_train)\n",
    "#Predict Output \n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "y_NBB_price_values_prediction = model_NBB_price.predict(X_NBB_price_v_test)\n",
    "score_NBB_price_values = metrics.accuracy_score(y_NBB_price_values_test, y_NBB_price_values_prediction)\n",
    "print(\"Price Points:\",\"Naive Bayes - Bernoulli:\",\"values:\",\"Accuracy:\",score_NBB_price_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "X_NBB_price = rawData['description'].values\n",
    "y_NBB_price_bins = rawData['price_bins'].values\n",
    "\n",
    "X_NBB_price_train, X_NBB_price_test, y_NBB_price_bins_train, y_NBB_price_bins_test = train_test_split(X_NBB_price, y_NBB_price_bins, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize training descriptions\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(X_NBB_price_train)\n",
    "X_NBB_price_v_train = vectorizer.transform(X_NBB_price_train)\n",
    "X_NBB_price_v_test  = vectorizer.transform(X_NBB_price_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price Points: Naive Bayes - Bernoulli: bins: Accuracy: 0.6067796610169491\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#Create a BernoulliNB Classifier\n",
    "model_NBB_price = BernoulliNB()\n",
    "# Train the model using the training sets\n",
    "model_NBB_price.fit(X_NBB_price_v_train,y_NBB_price_bins_train)\n",
    "#Predict Output \n",
    "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "y_NBB_price_bins_prediction = model_NBB_price.predict(X_NBB_price_v_test)\n",
    "score_NBB_price_bins = metrics.accuracy_score(y_NBB_price_bins_test, y_NBB_price_bins_prediction)\n",
    "print(\"Price Points:\",\"Naive Bayes - Bernoulli:\",\"bins:\",\"Accuracy:\",score_NBB_price_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review Points: Logistic Regression: values: Accuracy: 0.10847457627118644\n",
      "Review Points: Logistic Regression: bins: Accuracy: 0.1\n",
      "Review Points: Random forests: values: Accuracy: 0.08983050847457627\n",
      "Review Points: Random forests: bins: Accuracy: 0.4864406779661017\n",
      "Review Points: Naive Bayes - Multinomial: values: Accuracy: 0.08983050847457627\n",
      "Review Points: Naive Bayes - Multinomial: bins: Accuracy: 0.5050847457627119\n",
      "Review Points: Naive Bayes - Bernoulli: values: Accuracy: 0.09152542372881356\n",
      "Review Points: Naive Bayes - Bernoulli: bins: Accuracy: 0.488135593220339\n",
      "Price: Logistic Regression: values: Accuracy: 0.0847457627118644\n",
      "Price: Logistic Regression: bins: Accuracy: 0.5898305084745763\n",
      "Price: Random forests: values: Accuracy: 0.12372881355932204\n",
      "Price: Random forests: bins: Accuracy: 0.5949152542372881\n",
      "Price: Naive Bayes - Multinomial: values: Accuracy: 0.03559322033898305\n",
      "Price: Naive Bayes - Multinomial: bins: Accuracy: 0.0\n",
      "Price: Naive Bayes - Bernoulli: values: Accuracy: 0.1\n",
      "Price: Naive Bayes - Bernoulli: bins: Accuracy: 0.6067796610169491\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "print(\"Review Points:\",\"Logistic Regression:\",\"values:\",\"Accuracy:\",score_LR_rp_values)\n",
    "print(\"Review Points:\",\"Logistic Regression:\",\"bins:\",\"Accuracy:\",score_LR_rp_bins)\n",
    "\n",
    "print(\"Review Points:\",\"Random forests:\",\"values:\",\"Accuracy:\",score_RF_rp_values)\n",
    "print(\"Review Points:\",\"Random forests:\",\"bins:\",\"Accuracy:\",score_RF_rp_bins)\n",
    "\n",
    "print(\"Review Points:\",\"Naive Bayes - Multinomial:\",\"values:\",\"Accuracy:\",score_NBM_rp_values)\n",
    "print(\"Review Points:\",\"Naive Bayes - Multinomial:\",\"bins:\",\"Accuracy:\",score_NBM_rp_bins)\n",
    "\n",
    "print(\"Review Points:\",\"Naive Bayes - Bernoulli:\",\"values:\",\"Accuracy:\",score_NBB_rp_values)\n",
    "print(\"Review Points:\",\"Naive Bayes - Bernoulli:\",\"bins:\",\"Accuracy:\",score_NBB_rp_bins)\n",
    "\n",
    "print(\"Price:\",\"Logistic Regression:\",\"values:\",\"Accuracy:\",score_LR_price_values)\n",
    "print(\"Price:\",\"Logistic Regression:\",\"bins:\",\"Accuracy:\",score_LR_price_bins)\n",
    "\n",
    "print(\"Price:\",\"Random forests:\",\"values:\",\"Accuracy:\",score_RF_price_values)\n",
    "print(\"Price:\",\"Random forests:\",\"bins:\",\"Accuracy:\",score_RF_price_bins)\n",
    "\n",
    "print(\"Price:\",\"Naive Bayes - Multinomial:\",\"values:\",\"Accuracy:\",score_NBM_price_values)\n",
    "print(\"Price:\",\"Naive Bayes - Multinomial:\",\"bins:\",\"Accuracy:\",score_NBM_price_bins)\n",
    "\n",
    "print(\"Price:\",\"Naive Bayes - Bernoulli:\",\"values:\",\"Accuracy:\",score_NBB_price_values)\n",
    "print(\"Price:\",\"Naive Bayes - Bernoulli:\",\"bins:\",\"Accuracy:\",score_NBB_price_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
