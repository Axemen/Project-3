{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whiskey Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 7, 27, 21, 1, 16, 281030)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime as dt\n",
    "dt.utcnow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# machine learning specific libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "# model specific libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import SVC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['row_caller', 'Maker', 'distilled', 'age in cast', 'ABV', 'Blended',\n",
       "       'Bourbon', 'Flavored', 'Other', 'Rye', 'Scotch', 'single blended grain',\n",
       "       'single blended malt', 'world', 'review score', 'price', 'style',\n",
       "       'country', 'row_other', 'description'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "rawData = pd.read_csv(os.path.join(\"clean-data\",\"Whiskey_data\",\"Whiskey_Advocate_All_scraped_KHupdate-with-description.csv\"), encoding='iso-8859-1' )\n",
    "rawData.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean data\n",
    "rawData.dropna(how = 'all',inplace=True)\n",
    "rawData.dropna(subset=['description', 'price'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_caller</th>\n",
       "      <th>Maker</th>\n",
       "      <th>distilled</th>\n",
       "      <th>age in cast</th>\n",
       "      <th>ABV</th>\n",
       "      <th>Blended</th>\n",
       "      <th>Bourbon</th>\n",
       "      <th>Flavored</th>\n",
       "      <th>Other</th>\n",
       "      <th>Rye</th>\n",
       "      <th>Scotch</th>\n",
       "      <th>single blended grain</th>\n",
       "      <th>single blended malt</th>\n",
       "      <th>world</th>\n",
       "      <th>review score</th>\n",
       "      <th>price</th>\n",
       "      <th>style</th>\n",
       "      <th>country</th>\n",
       "      <th>row_other</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Johnnie Walker</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>225</td>\n",
       "      <td>Blended Scotch Whisky</td>\n",
       "      <td>UK</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Magnificently powerful and intense. Caramels, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Black Bowmore</td>\n",
       "      <td>1964.0</td>\n",
       "      <td>42 year old</td>\n",
       "      <td>40.50%</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>97</td>\n",
       "      <td>4500</td>\n",
       "      <td>Single Malt Scotch</td>\n",
       "      <td>UK</td>\n",
       "      <td>3.0</td>\n",
       "      <td>What impresses me most is how this whisky evol...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   row_caller           Maker  distilled  age in cast     ABV  Blended  \\\n",
       "0           1  Johnnie Walker        NaN          NaN  40.00%        1   \n",
       "1           2   Black Bowmore     1964.0  42 year old  40.50%        0   \n",
       "\n",
       "   Bourbon  Flavored  Other  Rye  Scotch  single blended grain  \\\n",
       "0        0         0      0    0       1                     0   \n",
       "1        0         0      0    0       1                     0   \n",
       "\n",
       "   single blended malt  world  review score  price                  style  \\\n",
       "0                    0      0            97    225  Blended Scotch Whisky   \n",
       "1                    1      0            97   4500     Single Malt Scotch   \n",
       "\n",
       "  country  row_other                                        description  \n",
       "0      UK        2.0  Magnificently powerful and intense. Caramels, ...  \n",
       "1      UK        3.0  What impresses me most is how this whisky evol...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# head data\n",
    "rawData.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review points bin\n",
    "rp_bins = [(0,75), (75,80), (80,85), (85,90), (90,95), (95, 100)]\n",
    "\n",
    "# find bin based on value\n",
    "def find_rp_bin(value):\n",
    "    \n",
    "    for i in range(0, len(rp_bins)):\n",
    "        if rp_bins[i][0] <= value < rp_bins[i][1]:\n",
    "            return rp_bins[i][0] #lower end of the bin is returned\n",
    "    return -1\n",
    "\n",
    "# fill y value\n",
    "rawData['rp_bins'] = rawData['review score'].apply(find_rp_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 625\n"
     ]
    }
   ],
   "source": [
    "# drop bottom 5 % and top 5 % based upon price\n",
    "bottom5 = np.percentile(rawData['price'],5,axis=0, interpolation='lower')\n",
    "top5 = np.percentile(rawData['price'],95,axis=0, interpolation='lower')\n",
    "print(bottom5,top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData = rawData[rawData.price >= 25]\n",
    "rawData = rawData[rawData.price <= 625]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 79 127 625\n"
     ]
    }
   ],
   "source": [
    "# price quartiles\n",
    "Q1 = np.percentile(rawData['price'],25,axis=0, interpolation='lower')\n",
    "Q2 = np.percentile(rawData['price'],50,axis=0, interpolation='lower')\n",
    "Q3 = np.percentile(rawData['price'],75,axis=0, interpolation='lower')\n",
    "Q4 = np.percentile(rawData['price'],100,axis=0, interpolation='lower')\n",
    "print(Q1,Q2,Q3,Q4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price bin\n",
    "price_bins = [(0,Q1), (Q1,Q2), (Q2,Q3), (Q3,Q4+1)]\n",
    "\n",
    "# find bin based on value\n",
    "def find_price_bin(value):\n",
    "    price = 0\n",
    "    for i in range(0, len(price_bins)):\n",
    "        if price_bins[i][0] <= value < price_bins[i][1]:\n",
    "            return price_bins[i][0] #lower end of the bin is returned\n",
    "    return -1\n",
    "\n",
    "# \n",
    "rawData['price_bins'] = rawData['price'].apply(find_price_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 50), (50, 79), (79, 127), (127, 626)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price_bins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LogisticRegressionModel(dataset,textColumn,yColumn):\n",
    "    # input:\n",
    "    #   dataset: unrestricted dataset\n",
    "    #   textColumn: column name containing text that will be analysed for machine learning\n",
    "    #   yColumn: column name containing the label\n",
    "    # return\n",
    "    #   LogisticRegressionModel_score\n",
    "\n",
    "    # vectorize description: take the words of each description and create a vocabulary of all the unique words in the descriptions.\n",
    "    vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "    vectorizer.fit(dataset[textColumn])\n",
    "    # create vector with all words for each description = Bag-of-words (BOW) model\n",
    "    vectorizer.transform(dataset[textColumn]).toarray()\n",
    "\n",
    "    #  split data\n",
    "    X = dataset[textColumn].values\n",
    "    y = dataset[yColumn].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)\n",
    "    \n",
    "    try:    \n",
    "        # vectorize training descriptions\n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizer.fit(X_train)\n",
    "        X_v_train = vectorizer.transform(X_train)\n",
    "        X_v_test  = vectorizer.transform(X_test)\n",
    "\n",
    "        # logistic regression classification model \n",
    "#         classifier = LogisticRegression(solver='liblinear',multi_class='auto')\n",
    "        classifier = LogisticRegression(solver='newton-cg',multi_class='auto')\n",
    "        classifier.fit(X_v_train, y_train) # vectorized training data\n",
    "        LogisticRegressionModel_score = classifier.score(X_v_test, y_test)\n",
    "    except:\n",
    "        LogisticRegressionModel_score = 0\n",
    "    \n",
    "    return LogisticRegressionModel_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForestModel(dataset,textColumn,yColumn):\n",
    "    # input:\n",
    "    #   dataset: unrestricted dataset\n",
    "    #   textColumn: column name containing text that will be analysed for machine learning\n",
    "    #   yColumn: column name containing the label\n",
    "    # return\n",
    "    #   RandomForestModel_score\n",
    "\n",
    "    #  split data\n",
    "    X = dataset[textColumn].values\n",
    "    y = dataset[yColumn].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)\n",
    "    \n",
    "    try:\n",
    "        # vectorize training descriptions\n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizer.fit(X_train)\n",
    "        X_v_train = vectorizer.transform(X_train)\n",
    "        X_v_test  = vectorizer.transform(X_test)\n",
    "\n",
    "        # Random Forest classification model\n",
    "        classifier = RandomForestClassifier(n_estimators=200)\n",
    "        classifier.fit(X_v_train, y_train) # vectorized training data\n",
    "        RandomForestModel_score = classifier.score(X_v_test, y_test)\n",
    "    except:\n",
    "        RandomForestModel_score = 0\n",
    "    \n",
    "    return RandomForestModel_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - Multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayesMultinomialModel(dataset,textColumn,yColumn):\n",
    "    # input:\n",
    "    #   dataset: unrestricted dataset\n",
    "    #   textColumn: column name containing text that will be analysed for machine learning\n",
    "    #   yColumn: column name containing the label\n",
    "    # return\n",
    "    #   NaiveBayesMultinomialModel_score\n",
    "\n",
    "    #  split data\n",
    "    X = dataset[textColumn].values\n",
    "    y = dataset[yColumn].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)\n",
    "    \n",
    "    # vectorize training descriptions\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(X_train)\n",
    "    X_v_train = vectorizer.transform(X_train)\n",
    "    X_v_test  = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Naive Bayes - Multinomial - classification model\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(X_v_train, y_train) # vectorized training data\n",
    "    MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "    NaiveBayesMultinomialModel_score = metrics.accuracy_score(y_test, classifier.predict(X_v_test))\n",
    "    \n",
    "    return NaiveBayesMultinomialModel_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NaiveBayesBernoulliModel(dataset,textColumn,yColumn):\n",
    "    # input:\n",
    "    #   dataset: unrestricted dataset\n",
    "    #   textColumn: column name containing text that will be analysed for machine learning\n",
    "    #   yColumn: column name containing the label\n",
    "    # return\n",
    "    #   NaiveBayesBernoulliModel_score\n",
    "\n",
    "    #  split data\n",
    "    X = dataset[textColumn].values\n",
    "    y = dataset[yColumn].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)\n",
    "    \n",
    "    # vectorize training descriptions\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(X_train)\n",
    "    X_v_train = vectorizer.transform(X_train)\n",
    "    X_v_test  = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Naive Bayes - Bernoulli - classification model\n",
    "    classifier = BernoulliNB()\n",
    "    classifier.fit(X_v_train, y_train) # vectorized training data\n",
    "    BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)\n",
    "    NaiveBayesBernoulliModel_score = metrics.accuracy_score(y_test, classifier.predict(X_v_test))\n",
    "    \n",
    "    return NaiveBayesBernoulliModel_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SupportVectorMachineModel(dataset,textColumn,yColumn):\n",
    "    # input:\n",
    "    #   dataset: unrestricted dataset\n",
    "    #   textColumn: column name containing text that will be analysed for machine learning\n",
    "    #   yColumn: column name containing the label\n",
    "    # return\n",
    "    #   SupportVectorMachineModel_score\n",
    "\n",
    "    #  split data\n",
    "    X = dataset[textColumn].values\n",
    "    y = dataset[yColumn].values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1000)\n",
    "    \n",
    "    # vectorize training descriptions\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(X_train)\n",
    "    X_v_train = vectorizer.transform(X_train)\n",
    "    X_v_test  = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Naive Bayes - Bernoulli - classification model\n",
    "    classifier = SVC(gamma='auto')\n",
    "    classifier.fit(X_v_train, y_train) # vectorized training data\n",
    "    SupportVectorMachineModel_score = metrics.accuracy_score(y_test, classifier.predict(X_v_test))\n",
    "    \n",
    "    return SupportVectorMachineModel_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AllModelsApplied(dataset,check):\n",
    "    # Logistic Regression\n",
    "    LRM_ReviewPoints_Value_score = LogisticRegressionModel(dataset,'description','review score')\n",
    "    LRM_ReviewPoints_Bins_score = LogisticRegressionModel(dataset,'description','rp_bins')\n",
    "    LRM_Price_Value_score = LogisticRegressionModel(dataset,'description','price')\n",
    "    LRM_Price_Bins_score = LogisticRegressionModel(dataset,'description','price_bins')\n",
    "    Outcomes.append(round(LRM_ReviewPoints_Value_score,2))\n",
    "    Outcomes.append(round(LRM_ReviewPoints_Bins_score,2))\n",
    "    Outcomes.append(round(LRM_Price_Value_score,2))\n",
    "    Outcomes.append(round(LRM_Price_Bins_score,2))\n",
    "\n",
    "    # Random Forest\n",
    "    RF_ReviewPoints_Value_score = RandomForestModel(dataset,'description','review score')\n",
    "    RF_ReviewPoints_Bins_score = RandomForestModel(dataset,'description','rp_bins')\n",
    "    RF_Price_Value_score = RandomForestModel(dataset,'description','price')\n",
    "    RF_Price_Bins_score = RandomForestModel(dataset,'description','price_bins')\n",
    "    Outcomes.append(round(RF_ReviewPoints_Value_score,2))\n",
    "    Outcomes.append(round(RF_ReviewPoints_Bins_score,2))\n",
    "    Outcomes.append(round(RF_Price_Value_score,2))\n",
    "    Outcomes.append(round(RF_Price_Bins_score,2))\n",
    "\n",
    "    # Naive Bayes - Multinomial\n",
    "    NBM_ReviewPoints_Value_score = NaiveBayesMultinomialModel(dataset,'description','review score')\n",
    "    NBM_ReviewPoints_Bins_score = NaiveBayesMultinomialModel(dataset,'description','rp_bins')\n",
    "    NBM_Price_Value_score = NaiveBayesMultinomialModel(dataset,'description','price')\n",
    "    NBM_Price_Bins_score = NaiveBayesMultinomialModel(dataset,'description','price_bins')\n",
    "    Outcomes.append(round(NBM_ReviewPoints_Value_score,2))\n",
    "    Outcomes.append(round(NBM_ReviewPoints_Bins_score,2))\n",
    "    Outcomes.append(round(NBM_Price_Value_score,2))\n",
    "    Outcomes.append(round(NBM_Price_Bins_score,2))\n",
    "\n",
    "    # Naive Bayes - Bernoulli\n",
    "    NBB_ReviewPoints_Value_score = NaiveBayesBernoulliModel(dataset,'description','review score')\n",
    "    NBB_ReviewPoints_Bins_score = NaiveBayesBernoulliModel(dataset,'description','rp_bins')\n",
    "    NBB_Price_Value_score = NaiveBayesBernoulliModel(dataset,'description','price')\n",
    "    NBB_Price_Bins_score = NaiveBayesBernoulliModel(dataset,'description','price_bins')\n",
    "    Outcomes.append(round(NBB_ReviewPoints_Value_score,2))\n",
    "    Outcomes.append(round(NBB_ReviewPoints_Bins_score,2))\n",
    "    Outcomes.append(round(NBB_Price_Value_score,2))\n",
    "    Outcomes.append(round(NBB_Price_Bins_score,2))\n",
    "    \n",
    "    # Support Vector Machines\n",
    "    SVM_ReviewPoints_Value_score = SupportVectorMachineModel(dataset,'description','review score')\n",
    "    SVM_ReviewPoints_Bins_score = SupportVectorMachineModel(dataset,'description','rp_bins')\n",
    "    SVM_Price_Value_score = SupportVectorMachineModel(dataset,'description','price')\n",
    "    if ( check != 'Q1' and check != 'Q2' and check != 'Q3' and check != 'Q4'):\n",
    "        SVM_Price_Bins_score = SupportVectorMachineModel(dataset,'description','price_bins')\n",
    "    else:\n",
    "        SVM_Price_Bins_score = 0\n",
    "    Outcomes.append(round(SVM_ReviewPoints_Value_score,2))\n",
    "    Outcomes.append(round(SVM_ReviewPoints_Bins_score,2))\n",
    "    Outcomes.append(round(SVM_Price_Value_score,2))\n",
    "    Outcomes.append(round(SVM_Price_Bins_score,2))\n",
    "        \n",
    "    return Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# header data\n",
    "Result = pd.DataFrame(columns=('Model','Feature','Full_Data','Q1_Q2','Q2_Q3','Q1','Q2','Q3','Q4'))\n",
    "Result['Model'] = ['Logistic Regression','Logistic Regression','Logistic Regression','Logistic Regression','Random Forest','Random Forest','Random Forest','Random Forest','Naive Bayes - Multinomial','Naive Bayes - Multinomial','Naive Bayes - Multinomial','Naive Bayes - Multinomial','Naive Bayes - Bernoulli','Naive Bayes - Bernoulli','Naive Bayes - Bernoulli','Naive Bayes - Bernoulli','SupportVectorMachine','SupportVectorMachine','SupportVectorMachine','SupportVectorMachine']\n",
    "Result['Feature'] = ['review score','review score bins','price','price bins','review score','review score bins','price','price bins','review score','review score bins','price','price bins','review score','review score bins','price','price bins','review score','review score bins','price','price bins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full data set\n",
    "Outcomes = []\n",
    "FilteredData = rawData.copy()\n",
    "AllModelsApplied(FilteredData,'full data set')\n",
    "Result['Full_Data'] = Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1/Q2\n",
    "Outcomes = []\n",
    "FilteredData = rawData.copy()\n",
    "indexNames = FilteredData[ (FilteredData['price'] >= Q2)].index\n",
    "FilteredData.drop(indexNames , inplace=True)\n",
    "AllModelsApplied(FilteredData,'Q1/Q2')\n",
    "Result['Q1_Q2'] = Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2/Q3\n",
    "Outcomes = []\n",
    "FilteredData = rawData.copy()\n",
    "indexNames = FilteredData[ (FilteredData['price'] < Q1)].index\n",
    "FilteredData.drop(indexNames , inplace=True)\n",
    "indexNames = FilteredData[ (FilteredData['price'] >= Q3)].index\n",
    "FilteredData.drop(indexNames , inplace=True)\n",
    "AllModelsApplied(FilteredData,'Q2/Q3')\n",
    "Result['Q2_Q3'] = Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1\n",
    "Outcomes = []\n",
    "FilteredData = rawData.copy()\n",
    "indexNames = FilteredData[ (FilteredData['price'] >= Q1)].index\n",
    "FilteredData.drop(indexNames , inplace=True)\n",
    "AllModelsApplied(FilteredData,'Q1')\n",
    "Result['Q1'] = Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2\n",
    "Outcomes = []\n",
    "FilteredData = rawData.copy()\n",
    "indexNames = FilteredData[ (FilteredData['price'] < Q1)].index\n",
    "FilteredData.drop(indexNames , inplace=True)\n",
    "indexNames = FilteredData[ (FilteredData['price'] >= Q2)].index\n",
    "FilteredData.drop(indexNames , inplace=True)\n",
    "AllModelsApplied(FilteredData,'Q2')\n",
    "Result['Q2'] = Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3\n",
    "Outcomes = []\n",
    "FilteredData = rawData.copy()\n",
    "indexNames = FilteredData[ (FilteredData['price'] < Q2)].index\n",
    "FilteredData.drop(indexNames , inplace=True)\n",
    "indexNames = FilteredData[ (FilteredData['price'] >= Q3)].index\n",
    "FilteredData.drop(indexNames , inplace=True)\n",
    "AllModelsApplied(FilteredData,'Q3')\n",
    "Result['Q3'] = Outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4\n",
    "Outcomes = []\n",
    "FilteredData = rawData.copy()\n",
    "indexNames = FilteredData[ (FilteredData['price'] < Q3)].index\n",
    "FilteredData.drop(indexNames , inplace=True)\n",
    "AllModelsApplied(FilteredData,'Q4')\n",
    "Result['Q4'] = Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Feature</th>\n",
       "      <th>Full_Data</th>\n",
       "      <th>Q1_Q2</th>\n",
       "      <th>Q2_Q3</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>review score</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>review score bins</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>price</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>price bins</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>review score</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>review score bins</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>price</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>price bins</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes - Multinomial</td>\n",
       "      <td>review score</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes - Multinomial</td>\n",
       "      <td>review score bins</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Naive Bayes - Multinomial</td>\n",
       "      <td>price</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive Bayes - Multinomial</td>\n",
       "      <td>price bins</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Naive Bayes - Bernoulli</td>\n",
       "      <td>review score</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Naive Bayes - Bernoulli</td>\n",
       "      <td>review score bins</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Naive Bayes - Bernoulli</td>\n",
       "      <td>price</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Naive Bayes - Bernoulli</td>\n",
       "      <td>price bins</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.58</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SupportVectorMachine</td>\n",
       "      <td>review score</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SupportVectorMachine</td>\n",
       "      <td>review score bins</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SupportVectorMachine</td>\n",
       "      <td>price</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SupportVectorMachine</td>\n",
       "      <td>price bins</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Model            Feature  Full_Data  Q1_Q2  Q2_Q3  \\\n",
       "0         Logistic Regression       review score       0.11   0.11   0.10   \n",
       "1         Logistic Regression  review score bins       0.47   0.50   0.47   \n",
       "2         Logistic Regression              price       0.07   0.12   0.09   \n",
       "3         Logistic Regression         price bins       0.44   0.63   0.57   \n",
       "4               Random Forest       review score       0.09   0.11   0.12   \n",
       "5               Random Forest  review score bins       0.46   0.50   0.54   \n",
       "6               Random Forest              price       0.08   0.14   0.13   \n",
       "7               Random Forest         price bins       0.48   0.68   0.64   \n",
       "8   Naive Bayes - Multinomial       review score       0.09   0.14   0.11   \n",
       "9   Naive Bayes - Multinomial  review score bins       0.50   0.52   0.54   \n",
       "10  Naive Bayes - Multinomial              price       0.08   0.10   0.12   \n",
       "11  Naive Bayes - Multinomial         price bins       0.49   0.69   0.59   \n",
       "12    Naive Bayes - Bernoulli       review score       0.08   0.13   0.13   \n",
       "13    Naive Bayes - Bernoulli  review score bins       0.49   0.50   0.53   \n",
       "14    Naive Bayes - Bernoulli              price       0.06   0.07   0.12   \n",
       "15    Naive Bayes - Bernoulli         price bins       0.50   0.70   0.58   \n",
       "16       SupportVectorMachine       review score       0.08   0.12   0.11   \n",
       "17       SupportVectorMachine  review score bins       0.42   0.45   0.50   \n",
       "18       SupportVectorMachine              price       0.05   0.06   0.09   \n",
       "19       SupportVectorMachine         price bins       0.29   0.55   0.55   \n",
       "\n",
       "      Q1    Q2    Q3    Q4  \n",
       "0   0.14  0.10  0.11  0.10  \n",
       "1   0.48  0.51  0.46  0.46  \n",
       "2   0.20  0.17  0.14  0.10  \n",
       "3   0.00  0.00  0.00  0.00  \n",
       "4   0.15  0.11  0.09  0.12  \n",
       "5   0.54  0.52  0.46  0.47  \n",
       "6   0.22  0.17  0.14  0.08  \n",
       "7   1.00  1.00  1.00  1.00  \n",
       "8   0.12  0.14  0.09  0.11  \n",
       "9   0.51  0.56  0.46  0.46  \n",
       "10  0.20  0.21  0.15  0.09  \n",
       "11  1.00  1.00  1.00  1.00  \n",
       "12  0.12  0.14  0.08  0.13  \n",
       "13  0.51  0.51  0.46  0.48  \n",
       "14  0.17  0.16  0.15  0.07  \n",
       "15  1.00  1.00  1.00  1.00  \n",
       "16  0.12  0.13  0.07  0.14  \n",
       "17  0.42  0.48  0.44  0.43  \n",
       "18  0.17  0.14  0.15  0.07  \n",
       "19  0.00  0.00  0.00  0.00  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result.to_csv('TextReviewOverview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 7, 27, 21, 23, 29, 224569)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.utcnow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
